---
title: "Manual de estadistica"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

#### Elaborado por:
* Alexander Nicholls

* Alejandro Tarazona


## Introducción
R Studio es un lenguaje de programación es una serie de reglas que están diseñadas para realizar procesos en una computadora, es un lenguaje para el cálculo estadístico y la generación de gráficos, que ofrece una gran variedad de técnicas estadísticas y gráficas.

A continuación definiremos e ilustraremos el como se pueden usar estas funciones dentro de este software y como se desarrollan.

## Lista de temas a tratar:

1. [Tipos de variables](#variables).
2. [Medidas de tendencia central](#medidas)
    + [Desviación Estándar](#desviacion)
    + [Moda](#moda)
    + [Media](#media)
    + [Mediana](#mediana)
    + [Maximo y minimo](#maxmin)
    + [Coeficiente de variación](#variacion)
3. [Medidas de asimetría y curtosis](#asicurt)
    + [Curtosis](#curtosis)
    + [Asimetria](#asimetria)
4. [Graficas](#graficas)
    + [Boxplot](#boxplot)
    + [Diagrama de barras](#barras)
    + [Diagrama de barras apiladas](#barras_apliadas)
    + [Historigrama](#histograma)
    + [Diagrama de pastel](#pastel)
    + [Diagrama de Pareto](#pareto)
    + [Diagrama de dispersión](#dispersion)
5. [Distribuciones](#distribuciones)
    + [Distribución normal](#normal)
    + [Distribución binomial](#binomial)
    + [Distribución de Poisson](#poisson)
6. [Probabilidad de eventos](#eventos)
8. [Teorema de bayes](#bayes)
8. [Chi cuadrado](#chi)
7. [Intervalos de confianza](#confianza)
    + [T-Test](#ttest)
    + [Anova](#anova)
8. [Pruebas de hipotesis](#pruebas)
    + [Prueba U de Mann-Whitney](#mann)
    + [Prueba de Shapiro-Wilks](#shapiro)
    + [Pruebas de Normalidad](#normalidad)
9. [Referencias](#referencias)

# 1. Tipos de variables: {#variables}

### Cuantitativas:
Son variables cuantitativas si los valores que toman son numericos.

* **Discretas**: Son discretas si sus valores son enteros.

    *Ejemplo: La edad*

* **Continuas**: Son continuas si entre dos valores son posibles infinitos valores intermedios.

    *Ejemplo: Velocidad promedio*

### Cualitativas:
Son cuantitativas si sus valores no son numericos.

* **Nominales**: Son nominales si sus valores no se pueden ordenar.

    *Ejemplo: Género, grupos sanguineos, Fumador(Sí, No)*

* **Ordinales**: Son ordinales si sus valores se pueden ordenar.

    *Ejemplo: Escolaridad, grado de satisfacción*

# 2. Medidas de tendencia central {#medidas}

### 2.1 Desviación estándar {#desviacion}

Para calcular el promedio de un conjunto de datos, se utiliza la función **sd()**, la cual retorna un resultado. A continuación, para explicar su uso se mostrará un ejemplo:

* Se realiza un cargue de datos en la variable x de la siguiente manera:

```{r}
desviacion<- c(0, 3, 6, 7, 9, 12)
```

* Ejecutamos la función y enviamos por parámetro la variable donde cargamos los datos.

```{r}
sd(desviacion)
```


### 2.2 Moda {#moda}

En un grupo determinado la **moda** es el valor con mayor frecuencia en una distribución de datos. Para calcularla usamos la función `table(variable)` el cual nos dice cuantas veces aparece cada número dentro de un vector, por lo que la moda será el número que más veces se repita.

Un ejemplo  lo podemos ver cargando los datos y haciendo uso de la función **table()**

```{r}
x<-seq(1,50,2)
table(x)
```

### 2.3 Media {#media}

En un espacio muestral la **Media** es el valor que resulta de sumar todos los numeros en un conjunto de datos y luego dividir el número resultante entre el número de valores en el conjunto.

Para este ejemplo tomaremos un conjunto de datos de la siguiente manera:

```{r}
arithmetic.mean <-function(x) {sum(x)/length(x)}
media<-c(4,7,6,7,5,8,9,4,12,3,5,6,8,7,4,10)
arithmetic.mean(media)
```

### 2.4 Mediana {#mediana}

La **mediana** representa el dato en la posición central dentro de un conjunto de datos cuando este se ordena de menor a mayor. Para realizar este análisis llamaremos a la función **median()**

Para este ejemplo tomaremos un vector y encontraremos su valor medio.

```{r}
mediana<-seq(1,50,2)
median(mediana)
```

### 2.5 Máximo y minimo {#maxmin}

El **máximo** y el **minimo** son respectivamente el valor más grande y el valor más pequeño en un grupo determinado. Para llamar a estas funciones usaremos **max()** y **min()**

Como ejemplo tomaremos un grupo de datos y utilizaremos ambas funciones.

   + Para el máximo:
```{r}
maximo<-seq(1,59,2)
max(maximo)
```
 + Para el minimo:
```{r}
minimo<-seq(1,59,2)
min(minimo)
```

### 2.6 Coeficiente de variación {#variacion}

El coeficiente de variación, representado con los simbolos $cv$, sirve para comparar conjuntos de datos y determinar que tan dispersos son. Esto es de mucha utilidad para determinar si la media de un conjunto de datos es una buena representación para estos.

Se puede calcular el coeficiente de variación de la siguiente forma: $CV = 100(\frac{\sigma}{\bar{x}})$. Donde $\sigma$ es la desviación estandar y $\bar{x}$ es la media.

|Variabilidad|Intervalo|
---|---|
Poco variable|[0-30]|
Variable|(30-70]|
Muy variable|(70-100]|

# 3. Medidas de asimetria y curtosis {#asicurt}

### 3.1 Curtosis {#curtosis}

Es la medida que indica que tan alta es la curva de distribución de los datos. Existen tres grupos para categorizar según su curtosis, las cuales son: *Planticúrtica, mesocúrtica y leptocúrtica*

![Imagen extraida de niversoformulas.com/estadistica/descriptiva/asimetria-curtosis](https://www.universoformulas.com/imagenes/estadistica/descriptiva/curtosis.jpg)

Para calcular la curtosis en R se usa el comando **kurtosis()**

```{r}
library(moments)
datos <- c(8,5,9,10,12,7,2,6,8,9,10,7,7)
kurtosis(datos)
```


### 3.2 Asimetría  {#asimetria}

Es la medida que indica la simetría de la distribución de los datos de una variable con respecto a la media de estos. Existen tres grupos para categorizar según su asimetría, los cuales son:  *Asimetría positivo, simétrica y simetría negativa*

![Imagen extraida de niversoformulas.com/estadistica/descriptiva/asimetria-curtosis](https://www.universoformulas.com/imagenes/estadistica/descriptiva/tipos-asimetria.jpg)

Para calcular la asimetría en R, se usa el comando **skewness()**

```{r}
library(moments)
datos <- c(8,5,9,10,12,7,2,6,8,9,10,7,7)
skewness(datos)
```


||$(-\inf, -0.5)$|$[0.5,0.5]$|$(0.5,\inf)$|
---|---|---|---|
**Curtosis**|Platicúrtica|Mesocúrtica|Leptocúrtica|
**Asimetría **|Asimetría positivo|Simétrica|Asimetría negativa|

# 4. Graficas {#graficas}


### 4.1 BOXPLOT {#boxplot}

El gráfico de Boxplot es el más utilizado para mostrar un resumen de una cantidad de datos, adicionalmente para comparar la distribución de varios grupos. Los datos cuantitativos son los únicos que se pueden representar con en esta grafica.

Este tipo de diagramas se crean en R mediante la función de **boxplot()**. Cuya sintaxis es:

    boxplot(x, Datos, Muesca, VarTam, Nombres, Main)

* **x:** Es un vector o una fórmula.
* **Datos:** Es el marco de datos.
* **Muesca:** Es un valor lógico. Establecer como VERDADERO para dibujar una muesca.
* **VarTam:** Es un valor lógico. Establecer como verdadero para dibujar el ancho del cuadro proporcional al tamaño de la muestra.
* **Nombres:** Son las etiquetas de grupo que se imprimirán debajo de cada diagrama de caja.
* **Main:** Se usa para dar un título al gráfico.

Ahora realizaremos un ejemplo:

```{r}
input<-mtcars[,c('mpg','cyl')]
boxplot(mpg~cyl, data = mtcars, xlab = "Number of Cylinders", ylab = "Miles Per Gallon", main = "Mileage Data", horizontal = T)
```

### 4.2 Diagrama de Barras {#barras}

Es un gráfico principalmente utilizado para representar datos de variables cuantitativas. Con el fin de mostrar la frecuencia con la que se han observado los datos de una variable discreta, con una barra para cada categoría de esta variable.

El comando para crear un diagrama de barras en R es **barplot()**, en el cual se pueden ajustar estos argumentos:

    barplot(datos,main,xlab,ylab,col)

* **main**: Es el título de la gráfica
* **xlab:** Es el texto que se encuentra sobre el eje x
* **ylab:** Es el texto que se encuentra sobre el eje y
* **col:** Son los colores que usara la grafica

```{r}
x<-c(1,3,2,1,2,2)
xf<-factor(x)
levels(xf)<-c("Primaria", "Secundaria", "Terciaria")
datos<-table(xf)
barplot(datos, main = "Gráfica de educación", xlab = "Nivel educativo", ylab = "Frecuencia", col = c("royalblue", "seagreen", "purple", "grey"))
```

### Diagrama de barras apiladas {#barras_apliadas}

Este diagrama se puede utilizar para mostrar dos o más conjuntos de datos uno segudo del otro, dejando evidencia las categorias que dividen a otra categoria más grande. Esto con el fin, de comparar las cantidades totales, ya sea porcentual o no.

Para realizar este grafico en R, se puede usar la libreria **ggplot2** y más especificamente usar la función **ggplot**


```{r}
library(ggplot2)
dat <- data.frame( Frutas=c("Manzana", "Manzana", "Naranja", "Naranja", "Naranja", "Naranja",
                      "Naranja", "Pera", "Pera", "Pera"), Genero=c("Hombre", "Mujer",
                        "Hombre", "Mujer", "Hombre", "Hombre", "Mujer", "Mujer",
                      "Mujer", "Hombre") )  

ggplot(dat, aes(y = Frutas)) + geom_bar(aes(fill = Genero), position = 'fill')
```


### 4.3 Historigrama {#histograma}

Es un grafico muy utilizado para representar la cuenta de cada dato (la frecuencia). Para la realización de este diagrama se pueden usar variables cuantitativas.

Para realizar un histograma es con la función **hist()** y se le pasa por parámetro el conjunto de datos numericos.

    hist(datos)

```{r}
x<-c(1, 1, 1, 2, 2, 3, 4, 4, 5, 5, 5)
hist(x)
```

### 4.4 Diagrama de Pastel {#pastel}

Es un gráfico al cual se acude muy frecuentemente para representar porcentajes, proporciones y frecuencias con variables cualitativas. 

La sintaxis para graficar es

	  Pie(proporciones,  labes = etiquetas, main = titulo)

* **x:** Lista con los valores
* **labels:** Descripción de las porciones.
* **radius:** Indica el radio (debe ser un valor entre -1 y 1)
* **col:** Paleta de colores
* **clockwise:** Valor lógico que indica el sentido en el que se representa el pie

```{r}
proporciones<-c(0.1,0.1,0.4,0.2,0.3)
etiquetas<-c('Etiqueta #1', 'Etiqueta #2', 'Etiqueta #3', 'Etiqueta #4', 'Etiqueta #5')
titulo = "Ejemplo de diagrama de pastel"
pie(proporciones, labels = etiquetas, main = titulo)
```

### 4.5 Diagrama de Pareto {#pareto}

Este diagrama es normalmente utilizado para realizar una comparación de variables cualitativas de forma ordenada. Para la lectura de este diagrama, hay que tener en cuenta la distribucion 80% y 20%.

Para construir este diagrama se utiliza el paquete qcc. Adicionalmente se usan los siguientes comandos:

    library(qcc)
    tipo <- Cantidad
    names(Tipo) <- Defecto
    pareto.chart(tipo)

Ejemplo:

```{r}
library(qcc)
defectos<-c(42,20,10,104)
names(defectos)<-c("A", "B", "D", "E")
pareto.chart(defectos, ylab = "Frecuencia", main = "Diagrama de pareto")
```


### 4.6 Diagrama de dispersión {#dispersion}

Este tipo de gráfico es usado para mostrar la relación entre dos variables numéricas continuas, usando puntos. Cada punto representa la intersección entre los valores de ambas variables. Para llamar a este diagrama usaremos la función **plot()**, a la cual le daremos vectores numéricos así como argumentos **X** y **Y**.

Para mostrar este diagrama usaremos el siguiente bloque de codigo:

```{r}
grasas <- read.table('http://verso.mat.uam.es/~joser.berrendero/datos/EdadPesoGrasas.txt', header = TRUE)
regresion <- lm(grasas ~ edad, data = grasas)
summary(regresion)
plot(grasas$edad, grasas$grasas, xlab='Edad', ylab='Grasas')
abline(regresion)
```




# 5. Distribuciones {#distribuciones}

### 5.1 Distribución normal {#normal}

La distribución normal es un modelo mediante el cual se aproxima el valor de una variable aleatoria a un valor ideal.Para obtener los valores basados en una distribución normal existen 4 funciones:

    dnorm: el cual devuelve resultados de la función de densidad. Se usa de la siguiente manera:
    `dnorm(x, mean = 0, sd = 1, log = F)`
    
```{r}
curve(dnorm(x, 0, 2), -8, 8)
```
    
### 5.2 Distribución binomial {#binomial}

Para la distribución binomial utilizamos la función **dbinom()** la cual da las probabilidades para varios valores de la variable binomial. Esta función requiere de tres argumentos los cuales son los siguientes:

* El primer argumento para esta función debe ser un vector de cuantiles (los valores posibles de la variable aleatoria X).
* El segundo y tercer argumento son los parámetros definidos de la distribución, a saber, n (el núimero de ensayos independientes) y p (la probabilidad de exito en cada ensayo).

Para explicar esta función tomaremos como ejemplo la novela de un autor que ha tenido gran exito hasta el punto que el 80% de los lectores ya la han leido. Un grupo de 4 personas son aficionados a la lectura y presentan los siguientes dos casos:

A. ¿Cuál es la probabilidad de que en el grupo hayan leído la novela 2 personas?

```{r}
dbinom(2,4,0.80)
```
B. La probabilidad de exito y la probabilidad de fracaso de leer la novela en un grupo de 4 personas.

```{r}
a=4
exito=0.80
fx.binomial=dbinom(0:4,a,exito)
fbb=pbinom(0:4,a,exito)
fx.binomial=data.frame(x=0:4, "F(X)"=fx.binomial, "SUM F(X)"=fbb)
fx.binomial
```


### 5.3 Distribución de Poisson {#poisson}

 La distribución de Poisson es un modelo que se aplica a las ocurrencias de algún suceso durante un intervalo determinado. la función para llamar a esta distribución  es **dpois()**.
 
* dpois(x, lambda, log = F): Devuelve resultados de la función de densidad.

Los parámetros que se pueden pasar a esta función son los siguientes:

```
x: Vector de cuartiles (valor entero positivo).
q: Vector de cuartiles.
p: Vector de probabilidades.
n: Número de valores aleatorios a devolver.
prob: Probabilidad de éxito en cada ensayo.
lambda: Vector de medias (Valor no negativo).
lower.tail: Parámetro booleano, si es TRUE las probabilidades son P[X ≤ x], de lo contrario P[X > x]
```

Para explicar esta distribución tomaremos como ejemplo una central telefónica en un hotel el cual recibe un número determinado de llamadas por minuto el cual sigue la distribución de Poisson con parámetro λ = 0.5 en el cual deberemos determinar:

A. Cual es la probabilidad de que en un minuto al azar se reciba solo una llamada, para el cual usaremos el siguiente código:

```{r}
dpois(c(1), 0.5)
```

B. Cual es la probabilidad de que en un minuto al azar se reciban como máximo dos llamadas, para el cual usaremos el siguiente bloque de código:

```{r}
ppois(c(2), 0.5)
```

C. Cual es la probabilidad de que en un minuto al azar se reciban mas de tres llamadas por minuto, para el cual usaremos el siguiente código:

```{r}
ppois(c(3), 0.5, lower.tail=F)
```

D. Cual es la probabilidad de que en un minuto al azar se reciban cinco llamadas en dos minutos, para lo cual usaremos el siguiente codigo:

```{r}
dpois(c(5), 1)
```

E. Cual es la probabilidad mínima que debe recibir la central por minuto para que exista una probabilidad del 98.5%, para el cual usaremos el siguiente codigo:

```{r}
qpois(c(0.985), 0.5)
```

---

# 6. Probabilidad de eventos {#eventos}

La probabilidad de eventos es la probabilidad de que ocurra un resultado o evento específico, tambié conocida como probabilidad pronosticada. Esto es una recopilación  de resultados contenido en un espacio muestral **S**.

Para entender este tema tomaremos como ejemplo un evento de que solamente se muestre la cara de una moneda. El primer paso es generar el espacio muestral.

 * Se cargan las variables para el espacio muestral y despues lo imprimimos para confirmar como se distribuyó.
 
```{r}
mone1<-c("Cara","Sello")
mone2<-mone1
EspMue<-expand.grid(mone1,mone2)
colnames(EspMue)<-c("Moneda 1", "Moneda 2")
EspMue
```
 
 * Una vez que tenemos el espacio muestral creado verificamos que es verdadero donde hay una cara en la moneda 1.
 
```{r}
x<-EspMue$`Moneda 1`=="Cara"
x
```
 
 * Realizamos el mismo proceso para verificar que sea verdadero donde haya una Cara en la moneda 2.
 
```{r}
y<-EspMue$`Moneda 2`=="Cara"
y
```
 
* Verificamos que sea verdadero donde haya solamente una cara.
```{r}
cara<-xor(x,y)
cara
```

* Finalmente generamos el evento.
```{r}
Evento<-EspMue[xor(x,y),]
Evento
```


# Teorema de Bayes{#bayes}

Permite calcular la probabilidad de que ocurra un evento, si se conocen las otras probabilidades que se encuentran en el mismo espacio muestral. 

El teorema de bayes se representa con la siguiente formula: 

$P(A_i|B) = \frac{P(B|A_i)P(A_i)}{P(B|A_1)+...+P(B|A_k)P(A_k)}$

*Ejemplo:*

![Extraido de rbjlabs](https://www.rbjlabs.com/wp-content/uploads/2018/06/teorema-de-bayes-ejemplo-238x300.png)
  
$P(A|R)=\frac{(0.2)(0.07)}{(0.2)(0.07)+(0.25)(0.08)+(0.4)(0.05)+(0.15)(0.09)}=0.2074$

# 7. Intervalos de confianza {#confianza}

### 7.1 T-Test {#ttest}

Esta prueba es un análisis usado para determinar la diferencia significativa entre los promedios de dos grupos y de esta manera entender si están relacionados en algunas características. Los datos a analizar deben tener distribución normal. La función a utilizar para realizar ese análisis es `t.test()`.

Para poder entender como funciona este análisis tomaremos el siguiente ejemplo:
 * Compararemos 2 muestras, ambas con variables aleatoreas.La primera muestra tendrá una **media de 10** mientras que la segunda tendrá una **media de 10.5** y finalmente aplicaremos la función `t.test()`
 
```{r}
x1 <- rnorm(100,10) #Esta será nuestra variable aleatoria de media 10
x2 <- rnorm(100,10.5) #Esta será nuestra variable aleatoria de media 10.5
test <- t.test(x1,x2) #Esta será nuestra prueba T de Student
print(test)
```
 

### 7.2 Anova {#anova}


Para el modelo de análisis de varianza (ANOVA) se pueden tomar dos o más grupos para comparar y de esta manera evaluar la importancia de uno o más factores; en este análisis se establece una hipótesis nula que dice que las medidas de la población son iguales y por otro lado se crea una hipótesis alternativa que establece que al menos una es diferente.

Para explicar este modelo podemos usar el siguiente ejemplo:

* Se quiere saber si los colores son atractivos para los insectos; para ello se diseñaron trampas con los siguientes colores: Amarillo, Azul, Blanco y Verde.

    Tomamos las dos variables, insectos que es nuestra variable de respuesta y colores que es nuestra variable factor. En este caso tomaremos los grupos y los pondremos en la consola para su análisis de la siguiente manera:
    
+ Para el grupo de insectos usaremos la siguiente muestra:
    `insectos <- c(16,11,20,21,14,7,37,32,15,25,39,41,21,12,14,17,13,17,45,59,48,46,38,47)`

+ Y para el grupo de colores usaremos la siguiente:
    `colores <- as.factor(c(rep(c("azul", "verde",  "blanco", "amarillo"), each =6)))` 
    
 + En este caso cada color se repetirá 6 veces para que los grupos a comparar sean del mismo tamaño.
    
+ Para realizar un análisis de Anova entre los dos grupos usamos el siguiente codigo:
    `fm = aov ( lm(insectos ~ colores) )`
    
+ Tambien, si queremos un resumen del análisis anterior utilizamos la funcion _summary_ de la siguiente manera:
    `summary(fm)`
    
+ Finalmente para ver los elementos generados por el análisis de Anova usamos el siguiente bloque de código:
    `names(fm)`
    
```{r}
require(stats)
insectos <- c(16,11,20,21,14,7,37,32,15,25,39,41,21,12,14,17,13,17,45,59,48,46,38,47)
colores <- as.factor(c(rep(c("azul", "verde",  "blanco", "amarillo"), each =6)))
tapply(insectos, colores, mean)
fm = aov ( lm(insectos ~ colores) )
summary(fm)
names(fm)
```
    
    
---

# 8. Pruebas de hipótesis {#pruebas}

### Chi cuadrado {#chi}
 
Es la prueba más utilizada para anlizar variables cualitativas. Esta prueba se realiza para evaluar la independencia de los datos, la cual consiste en evaluar probabilidad de una difrencia igual o mayor a la que existe entre los datos y las frecuencias esperadas segun la hipótesis nula.

*Ejemplo:*

Table: Observado

||Hombre|Mujer|Total|
---|---|---|---|
Apple|10|5|15|
Android|15|20|35|
Huawei|40|30|70|
||65|55|120|

Ahora se debe calcular el valor esperado de la siguiente forma para la celdas $\frac{(totalColumna)(totalFila)}{totalDatos}$
  
**Ejemplo** la primera celda: $\frac{(65)(15)}{120}=8.13$

Table: Esperado

||Hombre|Mujer|
---|---|---|
Apple|8,13|6,88|
Android|18,96|16,04|
Huawei|37,92|32,08|

Luego se halla el cuadrado de la diferencia del observado y el esperado, sobre la cantidad de los datos. $\frac{(observado-esperado)^2}{observado}$

||Hombre|Mujer|
---|---|---|
Apple|0,43|0,51|
Android|0,83|0,98|
Huawei|0,11|0,14|

Se suman los valores de la tabla, para este caso, $experimental=3$.

Luego procedemos a calcular el grado de liberdad, la formula para realizarlo es $(Filas-1)+(Columnas-1)$. Para este ejemplo $(3-1)(2-1)=2$

Adicionalmente, se tiene que buscar el valor critico en la distribución de chi cuadrado. Para esto se escoge la columna segun los grados de libertad. Como en este ejercicio no se dice cual es el grado de confianza, asumimos que es el 95%, por lo cual debemos buscar el valor segun $1-0.95=0.05$

![](https://image.slidesharecdn.com/tablachi-cuadrado-130922103507-phpapp02/95/tabla-chi-cuadrado-1-638.jpg?cb=1379846134)

En este caso el valor critico es $5,991$.

Para finalizar, se debe aceptar la hipotesis nula, la cual nos dice que no hay relacion entre los sistemas operativos y el genero.

### 8.1 Prueba U de Mann-Whitney {#mann}

La prueba U de Mann-whitney la aplicamos cuando tenemos 2 muestras y queremos saber si hay un diferencia significativa entre las magnitudes de la variable que estamos analizando; en este caso usamos Mann-Whitney cuando los requisitos para la prueba de T-Test o la prueba Z no se cumplen.

Para demostrar esta prueba llamaremos a la función **wilcox.test()** y usaremos el siguiente ejemplo:

* Supongamos que tenemos datos diagnósticos de 4 mujeres y 5 hombres. Todos fueron diagnosticados con diabetes y tenemos la edad a la cual se les descrubrió la enfermedad. Queremos saber si hay diferencia en la edad entre hombres y mujeres. Los datos son:

Siendo **H0** nuestra hipótesis por medio de la cual queremos saber si: *Existe diferencia en la edad entre Hombres y Mujeres.*

Hombres: {19,22,16,29,24},
Mujeres: {20,11,17,12}

```{r}
Hombres = c(19, 22, 16, 29, 24)
Mujeres = c(20, 11, 17, 12)
wilcox.test(Hombres, Mujeres)
```
Vemos que en este caso no podemos rechazar nuestra hipotesis **H0**.

### 8.2 Prueba de Shapiro-Wilks {#shapiro}

En la prueba de Shapiro-Wilks planteamos una hipótesis nula en la cual una muestra tomamos una muestra proveniente de una distribución normal, escogemos un nivel de significanza, por defecto 0,05 y tomamos una hipótesis alternativa que sostiene que la distribución no es normal.

Como resultados podemos tomar:

**H0**: Cuando la distribución es normal.
**H1**: Cuando la distribución no es normal.

Para realizar esta prueba usaremos la función **shapiro.test()**.

Tomaremos como ejemplo los siguientes grupos:

**Grupo A** :(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)
**Grupo B** :(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)

```{r}
Grupo.A = c(15, 12, 11, 18, 15, 15, 9, 19, 14, 13, 11, 12, 18, 15, 16, 14, 16, 17, 15, 17, 13, 14, 13, 15, 17, 19, 17, 18, 16, 14)
shapiro.test(Grupo.A)
Grupo.B = c(11, 16, 14, 18, 6, 8, 9, 14, 12, 12, 10, 15, 12, 9, 13, 16, 17, 12, 8, 7, 15, 5, 14, 13, 13, 12, 11, 13, 11, 7)
shapiro.test(Grupo.B)
```
Como podemos observar el valor de probabilidad **(p)** es muy superior a nuestro nivel elegido **(0,05)**, por lo que en este caso *no rechazamos la hipótesis nula*.

### 8.3 Pruebas de normalidad {normalidad}


---

# 9. Referencias {#referencias}

Asimetría y curtosis. (2020). Retrieved 31 May 2020, from https://www.universoformulas.com/estadistica/descriptiva/asimetria-curtosis

Coeficiente de variación. (2020). Retrieved 31 May 2020, from https://es.wikipedia.org/wiki/Coeficiente_de_variaci%C3%B3n

Diagrama de Pareto. (2020). Retrieved 31 May 2020, from https://es.wikipedia.org/wiki/Diagrama_de_Pareto

R boxplot() to Create Box Plot (With Numerous Examples). (2020). Retrieved 31 May 2020, from https://www.datamentor.io/r-programming/box-plot/

RPubs - Construcción de un diagrama de Pareto. (2020). Retrieved 31 May 2020, from https://rpubs.com/ctellez_gdl/58732

¿Qué Es ANOVA?. (2020). Retrieved 31 May 2020, from https://support.minitab.com/es-mx/minitab/18/help-and-how-to/modeling-statistics/anova/supporting-topics/basics/what-is-anova/

Prueba U de Mann-Whitney. (2020). Retrieved 31 May 2020, from  https://bookdown.org/dietrichson/metodos-cuantitativos/prueba-u-de-mann-whitney.html

Prueba de Shapiro-Wilks. (2020). Retrieved 31 May 2020, from https://bookdown.org/dietrichson/metodos-cuantitativos/test-de-normalidad.html

Pruebas de Normalidad. (2020). Retrieved 31 May 2020, from https://rpubs.com/MSiguenas/122473

Teorema de Bayes | Explicación detallada y ejemplos. (2020). Retrieved 1 June 2020, from https://www.rbjlabs.com/probabilidad-y-estadistica/teorema-de-bayes/
